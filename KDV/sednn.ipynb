{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "905cc23d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:00:50.656246Z",
     "start_time": "2024-06-10T10:00:44.091096Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\Anaconda\\intall\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\software\\Anaconda\\intall\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\software\\Anaconda\\intall\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\software\\Anaconda\\intall\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\software\\Anaconda\\intall\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\software\\Anaconda\\intall\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\zhizhi\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\zhizhi\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\zhizhi\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\zhizhi\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\zhizhi\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\zhizhi\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62861606",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:00:50.723245Z",
     "start_time": "2024-06-10T10:00:50.658246Z"
    }
   },
   "outputs": [],
   "source": [
    "RandomSeed = 1235\n",
    "np.random.seed(RandomSeed)\n",
    "tf.set_random_seed(RandomSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f661621c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T16:55:43.277296Z",
     "start_time": "2024-06-07T16:55:43.246296Z"
    }
   },
   "outputs": [],
   "source": [
    "class PtPINNsss:\n",
    "    # Initialize the class\n",
    "    def __init__(self, x, t, u, lb, ub, lbp,ubp, layers,weights_values,biases_values):\n",
    "        \n",
    "        X = np.concatenate([x, t], 1)\n",
    "\n",
    "        self.X = X\n",
    "        \n",
    "        self.x = X[:,0:1]\n",
    "        self.t = X[:,1:2]\n",
    "        \n",
    "        self.u = u      \n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.hsadasjd=0\n",
    "        self.ubp = ubp\n",
    "        self.lbp = lbp        \n",
    "        # Initialize NNs\n",
    "        self.layers = layers\n",
    "        self.hh=[]\n",
    "        self.hh1=[]      \n",
    "        \n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "        \n",
    "        value_float64 = 1.0 / math.tanh(0.5 * 5)\n",
    "        self.b = tf.constant(value_float64, dtype=tf.float64)\n",
    "        \n",
    "        value_float64=  1.0/(math.cosh(5*0.5)-1)       \n",
    "        \n",
    "        self.a = tf.constant(value_float64, dtype=tf.float64)  \n",
    "     \n",
    "        \n",
    "    \n",
    "        \n",
    "        self.weights_values = weights_values        \n",
    "        self.biases_values = biases_values    \n",
    "\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))    \n",
    "\n",
    "        self.x_f_tf = tf.placeholder(tf.float64, shape=[None, self.x.shape[1]])\n",
    "        self.t_f_tf = tf.placeholder(tf.float64, shape=[None, self.t.shape[1]])\n",
    "        \n",
    "        self.x_lb_tf = tf.placeholder(tf.float64, shape=[None, self.x.shape[1]])\n",
    "        self.t_b_tf = tf.placeholder(tf.float64, shape=[None, self.t.shape[1]])\n",
    "        self.x_ub_tf = tf.placeholder(tf.float64, shape=[None, self.x.shape[1]])\n",
    "        \n",
    "        self.x_tf = tf.placeholder(tf.float64, shape=[None, self.x.shape[1]])\n",
    "        self.t_tf = tf.placeholder(tf.float64, shape=[None, self.t.shape[1]])\n",
    "        \n",
    "        self.u_tf = tf.placeholder(tf.float64, shape=[None, self.u.shape[1]])\n",
    "\n",
    "        self.u_pred, _ ,self.uuuuuu = self.net_AC(self.x_tf, self.t_tf)\n",
    "        self.u_lb_pred, self.ux_lb_pred,_ = self.net_AC(self.x_lb_tf, self.t_b_tf)\n",
    "        self.u_ub_pred, self.ux_ub_pred,_ = self.net_AC(self.x_ub_tf, self.t_b_tf)\n",
    "\n",
    "        self.f_pred = self.net_f(self.x_f_tf, self.t_f_tf)\n",
    "        \n",
    "        self.lossS = tf.reduce_mean(tf.square(self.u_tf - self.u_pred))                                              \n",
    "        self.lossB = tf.reduce_mean(tf.square(self.u_lb_pred - self.u_ub_pred)) + tf.reduce_mean(tf.square(self.ux_lb_pred - self.ux_ub_pred))\n",
    "        self.lossfu =  tf.reduce_mean(tf.square(self.f_pred))    \n",
    "        \n",
    "\n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
    "\n",
    "        self.loss  =   self.lossS + 20 * self.lossB + self.lossfu\n",
    "             \n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)      \n",
    "\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
    "    \n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "        self.save = tf.train.Saver(max_to_keep=1)\n",
    "              \n",
    "    def initialize_NN(self, layers):        \n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers) \n",
    "        for l in range(0,num_layers-1):\n",
    "            W = tf.Variable(tf.zeros([layers[l], layers[l+1]], dtype=tf.float64), dtype=tf.float64)\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float64), dtype=tf.float64)\n",
    "            weights.append(W)\n",
    "            biases.append(b)        \n",
    "        return weights, biases\n",
    "    \n",
    "    \n",
    "    def initialize_NN2(self, layers):        \n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers) \n",
    "        for l in range(0,num_layers-1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float64), dtype=tf.float64)\n",
    "            weights.append(W)\n",
    "            biases.append(b)        \n",
    "        return weights, biases      \n",
    "    \n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]        \n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev, dtype=tf.float64))\n",
    "    \n",
    "    def custom_function(self,t):\n",
    "        \n",
    "        condition2 = tf.less_equal(t, 0.5)\n",
    "        b=2*(t-0.5)\n",
    "        return tf.where(condition2, tf.zeros_like(t), -2*b**3+3*b**2)\n",
    "\n",
    "    def neural_net(self, x,t, weights, biases,weights_values,biases_values):\n",
    "        tt=2*t\n",
    "        x = (x+1)/2\n",
    "        num_layers = len(weights) + 1\n",
    "        H = tf.concat([tt,x],1)\n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            W1 = weights_values[l]\n",
    "            b1 = biases_values[l]   \n",
    "            H0 = tf.add(tf.matmul(H, W), b)\n",
    "            H1 = tf.add(tf.matmul(H, W1), b1)\n",
    "            \n",
    "            B = self.custom_function(t)   \n",
    "            H0 = H0*B              \n",
    "            \n",
    "            H  = tf.add(H0,H1)\n",
    "            H =  tf.tanh(H)\n",
    "        \n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        W1 = weights_values[-1]\n",
    "        b1 = biases_values[-1]  \n",
    "        H0 = tf.add(tf.matmul(H, W), b)\n",
    "        \n",
    "        B = self.custom_function(t)     \n",
    "        H0 = H0*B            \n",
    "        \n",
    "        H1 = tf.add(tf.matmul(H, W1), b1) \n",
    "        H  = tf.add(H0,H1)      \n",
    "        Y = H\n",
    "        return Y\n",
    "    \n",
    "    def net_AC(self, x, t):\n",
    "        u = self.neural_net(x,t, self.weights, self.biases,self.weights_values, self.biases_values)\n",
    "        u_x = tf.gradients(u, x)[0]\n",
    "        u_t = tf.gradients(u, t)[0]\n",
    "        return u, u_x, u_t\n",
    "\n",
    "    def net_f(self, x, t):\n",
    "        u, u_x, u_t = self.net_AC(x, t)\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        u_xxx = tf.gradients(u_xx, x)[0]            \n",
    "        f_u = u_t +  u*u_x + 0.0025*u_xxx\n",
    "        return f_u\n",
    "    \n",
    "    def callback(self, loss, a,b,lossfu, lossS, lossB):\n",
    "        sss=self.hsadasjd\n",
    "        if sss%1000==0:\n",
    "            print('Loss: %.6e, Lossfu: %.3e, LossS: %.3e, LossB: %.3e ' % (loss, lossfu, lossS, lossB))\n",
    "        sss=sss+1\n",
    "        self.hsadasjd=sss \n",
    "        self.hh.append(a)      \n",
    "        self.hh1.append(b)\n",
    "        \n",
    "    def train(self, nIter, Nf, Nn, Nb):\n",
    "\n",
    "        X_train = self.lbp + (self.ubp-self.lbp)*lhs(2, Nf)\n",
    "        self.xtrain_f = X_train[:,0:1]\n",
    "        self.ttrain_f = X_train[:,1:2] \n",
    "        \n",
    "        X_lb_train = self.lbp + [0,self.ubp[1]-self.lbp[1]]*lhs(2, Nb)\n",
    "        self.xtrain_lb = X_lb_train[:,0:1]\n",
    "        self.ttrain_b = X_lb_train[:,1:2]\n",
    "        \n",
    "        X_ub_train = [self.ubp[0],self.lbp[1]] + [0,self.ubp[1]-self.lbp[1]]*lhs(2, Nb)\n",
    "        self.xtrain_ub = X_ub_train[:,0:1]\n",
    "        \n",
    "        tf_dict = {self.x_tf: self.x, self.t_tf: self.t, self.u_tf: self.u,\n",
    "                   self.x_lb_tf: self.xtrain_lb, self.t_b_tf: self.ttrain_b, \n",
    "                   self.x_ub_tf: self.xtrain_ub, \n",
    "                   self.x_f_tf: self.xtrain_f, self.t_f_tf: self.ttrain_f}\n",
    "\n",
    "        for it in range(nIter):\n",
    "            loss_value = self.sess.run(self.loss, tf_dict)\n",
    "            lossfu = self.sess.run(self.lossfu, tf_dict)\n",
    "            lossS = self.sess.run(self.lossS, tf_dict)\n",
    "            lossB = self.sess.run(self.lossB, tf_dict)\n",
    "            \n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "                \n",
    "            ab= self.sess.run(self.a)\n",
    "            self.hh.append(ab)       \n",
    "            abc= self.sess.run(self.b)\n",
    "            self.hh1.append(abc)    \n",
    "\n",
    "                \n",
    "            if it % 1000 == 0:\n",
    "                print('It: %d, Loss: %.6e, Lossfu: %.3e, LossS: %.3e, LossB: %.3e' % (it, loss_value, lossfu, lossS, lossB))\n",
    "                \n",
    "\n",
    "        \n",
    "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, method = 'L-BFGS-B', options = {'maxiter': 50000,'maxfun': 50000,'maxcor': 50,'maxls': 50,'ftol' : 1.0 * np.finfo(float).eps})                                                                                                         \n",
    "        self.optimizer.minimize(self.sess, feed_dict = tf_dict, fetches = [self.loss,self.a,self.b,  self.lossfu, self.lossS, self.lossB], loss_callback = self.callback)        \n",
    "                                    \n",
    "    \n",
    "    def predict(self, x, t):\n",
    "        \n",
    "        tf_dict = {self.x_tf: x, self.t_tf: t}\n",
    "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
    "        u_starssss = self.sess.run(self.uuuuuu, tf_dict)        \n",
    "        return u_star,u_starssss\n",
    "\n",
    "    def saver(self, string):\n",
    "        self.save.save(self.sess, 'ckpt/'+string)\n",
    "        \n",
    "        \n",
    "    def sssss(self):\n",
    "        return self.hh,  self.hh1           \n",
    "        \n",
    "        \n",
    "    def restore(self):\n",
    "        model_file = tf.train.latest_checkpoint('ckpt/')\n",
    "        self.save.restore(self.sess, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73933235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T16:55:43.293296Z",
     "start_time": "2024-06-07T16:55:43.277296Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15cf44c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T16:55:43.308296Z",
     "start_time": "2024-06-07T16:55:43.294296Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('bcweights.pkl', 'rb') as f:\n",
    "    weights_values = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8346a83d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T16:55:43.324295Z",
     "start_time": "2024-06-07T16:55:43.308296Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('bcweights1.pkl', 'rb') as f:\n",
    "    biases_values = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66a9d53e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:03:01.190321Z",
     "start_time": "2024-06-10T10:03:01.146321Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-92e10e471970>:108: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "It: 0, Loss: 2.635718e+01, Lossfu: 1.512e+00, LossS: 9.234e-10, LossB: 1.242e+00\n",
      "It: 1000, Loss: 3.469916e-02, Lossfu: 3.392e-02, LossS: 9.234e-10, LossB: 3.915e-05\n",
      "It: 2000, Loss: 2.689189e-02, Lossfu: 2.603e-02, LossS: 9.234e-10, LossB: 4.329e-05\n",
      "It: 3000, Loss: 2.383466e-02, Lossfu: 2.297e-02, LossS: 9.234e-10, LossB: 4.339e-05\n",
      "It: 4000, Loss: 3.297988e-02, Lossfu: 2.429e-02, LossS: 9.234e-10, LossB: 4.343e-04\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Loss: 2.293849e-02, Lossfu: 2.183e-02, LossS: 9.234e-10, LossB: 5.527e-05 \n",
      "Loss: 3.502695e-03, Lossfu: 3.221e-03, LossS: 9.234e-10, LossB: 1.410e-05 \n",
      "Loss: 2.189594e-03, Lossfu: 2.060e-03, LossS: 9.234e-10, LossB: 6.476e-06 \n",
      "Loss: 1.582286e-03, Lossfu: 1.511e-03, LossS: 9.234e-10, LossB: 3.575e-06 \n",
      "Loss: 1.208332e-03, Lossfu: 1.161e-03, LossS: 9.234e-10, LossB: 2.384e-06 \n",
      "Loss: 9.647576e-04, Lossfu: 9.239e-04, LossS: 9.234e-10, LossB: 2.044e-06 \n",
      "Loss: 7.857674e-04, Lossfu: 7.406e-04, LossS: 9.234e-10, LossB: 2.261e-06 \n",
      "Loss: 6.677757e-04, Lossfu: 6.283e-04, LossS: 9.234e-10, LossB: 1.976e-06 \n",
      "Loss: 5.773870e-04, Lossfu: 5.512e-04, LossS: 9.234e-10, LossB: 1.310e-06 \n",
      "Loss: 4.943726e-04, Lossfu: 4.741e-04, LossS: 9.234e-10, LossB: 1.013e-06 \n",
      "Loss: 4.413173e-04, Lossfu: 4.167e-04, LossS: 9.234e-10, LossB: 1.232e-06 \n",
      "Loss: 3.997831e-04, Lossfu: 3.767e-04, LossS: 9.234e-10, LossB: 1.154e-06 \n",
      "Loss: 3.568335e-04, Lossfu: 3.305e-04, LossS: 9.234e-10, LossB: 1.316e-06 \n",
      "Loss: 3.314389e-04, Lossfu: 3.050e-04, LossS: 9.234e-10, LossB: 1.322e-06 \n",
      "Loss: 3.087519e-04, Lossfu: 2.846e-04, LossS: 9.234e-10, LossB: 1.208e-06 \n",
      "Loss: 2.906039e-04, Lossfu: 2.680e-04, LossS: 9.234e-10, LossB: 1.128e-06 \n",
      "Loss: 2.704072e-04, Lossfu: 2.504e-04, LossS: 9.234e-10, LossB: 1.002e-06 \n",
      "Loss: 2.493322e-04, Lossfu: 2.326e-04, LossS: 9.234e-10, LossB: 8.364e-07 \n",
      "Loss: 2.324862e-04, Lossfu: 2.183e-04, LossS: 9.234e-10, LossB: 7.102e-07 \n",
      "Loss: 2.164170e-04, Lossfu: 2.035e-04, LossS: 9.234e-10, LossB: 6.465e-07 \n",
      "Loss: 2.066903e-04, Lossfu: 1.932e-04, LossS: 9.234e-10, LossB: 6.721e-07 \n",
      "Loss: 1.953648e-04, Lossfu: 1.828e-04, LossS: 9.234e-10, LossB: 6.262e-07 \n",
      "Loss: 1.853903e-04, Lossfu: 1.736e-04, LossS: 9.234e-10, LossB: 5.874e-07 \n",
      "Loss: 1.751649e-04, Lossfu: 1.635e-04, LossS: 9.234e-10, LossB: 5.843e-07 \n",
      "Loss: 1.637469e-04, Lossfu: 1.527e-04, LossS: 9.234e-10, LossB: 5.540e-07 \n",
      "Loss: 1.526823e-04, Lossfu: 1.427e-04, LossS: 9.234e-10, LossB: 4.993e-07 \n",
      "Loss: 1.462303e-04, Lossfu: 1.364e-04, LossS: 9.234e-10, LossB: 4.908e-07 \n",
      "Loss: 1.407672e-04, Lossfu: 1.306e-04, LossS: 9.234e-10, LossB: 5.078e-07 \n",
      "Loss: 1.350677e-04, Lossfu: 1.259e-04, LossS: 9.234e-10, LossB: 4.581e-07 \n",
      "Loss: 1.305343e-04, Lossfu: 1.214e-04, LossS: 9.234e-10, LossB: 4.542e-07 \n",
      "Loss: 1.269768e-04, Lossfu: 1.180e-04, LossS: 9.234e-10, LossB: 4.498e-07 \n",
      "Loss: 1.231804e-04, Lossfu: 1.138e-04, LossS: 9.234e-10, LossB: 4.670e-07 \n",
      "Loss: 1.199374e-04, Lossfu: 1.112e-04, LossS: 9.234e-10, LossB: 4.349e-07 \n",
      "Loss: 1.168015e-04, Lossfu: 1.083e-04, LossS: 9.234e-10, LossB: 4.237e-07 \n",
      "Loss: 1.136824e-04, Lossfu: 1.054e-04, LossS: 9.234e-10, LossB: 4.162e-07 \n",
      "Loss: 1.097405e-04, Lossfu: 1.011e-04, LossS: 9.234e-10, LossB: 4.302e-07 \n",
      "Loss: 1.050587e-04, Lossfu: 9.654e-05, LossS: 9.234e-10, LossB: 4.258e-07 \n",
      "Loss: 1.006536e-04, Lossfu: 9.229e-05, LossS: 9.234e-10, LossB: 4.182e-07 \n",
      "Loss: 9.704194e-05, Lossfu: 8.896e-05, LossS: 9.234e-10, LossB: 4.042e-07 \n",
      "Loss: 9.437388e-05, Lossfu: 8.624e-05, LossS: 9.234e-10, LossB: 4.065e-07 \n",
      "Loss: 9.154408e-05, Lossfu: 8.336e-05, LossS: 9.234e-10, LossB: 4.090e-07 \n",
      "Loss: 8.864813e-05, Lossfu: 8.067e-05, LossS: 9.234e-10, LossB: 3.986e-07 \n",
      "Loss: 8.529590e-05, Lossfu: 7.773e-05, LossS: 9.234e-10, LossB: 3.780e-07 \n",
      "Loss: 8.234077e-05, Lossfu: 7.420e-05, LossS: 9.234e-10, LossB: 4.068e-07 \n",
      "Loss: 7.998707e-05, Lossfu: 7.215e-05, LossS: 9.234e-10, LossB: 3.917e-07 \n",
      "Loss: 7.780892e-05, Lossfu: 6.994e-05, LossS: 9.234e-10, LossB: 3.932e-07 \n",
      "Loss: 7.519915e-05, Lossfu: 6.760e-05, LossS: 9.234e-10, LossB: 3.799e-07 \n",
      "Loss: 7.309248e-05, Lossfu: 6.547e-05, LossS: 9.234e-10, LossB: 3.813e-07 \n",
      "Loss: 7.123472e-05, Lossfu: 6.357e-05, LossS: 9.234e-10, LossB: 3.831e-07 \n",
      "Loss: 6.873769e-05, Lossfu: 6.087e-05, LossS: 9.234e-10, LossB: 3.933e-07 \n",
      "Loss: 6.639387e-05, Lossfu: 5.861e-05, LossS: 9.234e-10, LossB: 3.891e-07 \n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 0.000066\n",
      "  Number of iterations: 45546\n",
      "  Number of functions evaluations: 50001\n",
      "randorm seed: 1235\n",
      "Error2 u: 9.407912e-03\n",
      "Error1 u: 2.587443e-03\n",
      "Errorf u: 4.124001e-02\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "           \n",
    "    \n",
    "    # Doman bounds\n",
    "    lb = np.array([-1, 0])\n",
    "    ub = np.array([1, 0.5])\n",
    "    \n",
    "    lb1 = np.array([-1, 0.5])\n",
    "    ub1 = np.array([1, 1.0]) \n",
    "    \n",
    "    layers = [2,50,50,50,50,1]\n",
    "    \n",
    "    data = scipy.io.loadmat('kdv.mat')\n",
    "    \n",
    "    t = data['t'].flatten()[:,None]\n",
    "    x = data['x'].flatten()[:,None]\n",
    "    Exact = data['usol']\n",
    "    \n",
    "    X, T = np.meshgrid(x,t)\n",
    "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "    u_star = Exact.T.flatten()[:,None]\n",
    "\n",
    "    def IC(x):\n",
    "        u = np.cos(np.pi*x)\n",
    "        return u\n",
    "\n",
    "    N0 = 2400\n",
    "    x=np.linspace(-1,1,N0).flatten()[:,None]  \n",
    "    X0 =x\n",
    "    T0 = np.full((N0,1), lb[1])\n",
    "    U0 = IC(X0)\n",
    "      \n",
    "    model2 = PtPINNsss(X0, T0, U0, lb, ub,lb1, ub1, layers,weights_values,biases_values)                        \n",
    "    model2.train(5000 ,20000, 2400, 2400)  \n",
    "    model2.saver('testmodel.ckpt')\n",
    "\n",
    "    u_pred ,_= model2.predict(X_star[:,0:1],X_star[:,1:2])\n",
    "\n",
    "    erroru = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "    erroru1 = np.linalg.norm(u_star-u_pred,1)/len(X_star)\n",
    "    erroruinf = np.linalg.norm(u_star-u_pred,np.inf)\n",
    "    \n",
    "    print('randorm seed: %d' % (RandomSeed))\n",
    "\n",
    "    print('Error2 u: %e' % (erroru))\n",
    "    print('Error1 u: %e' % (erroru1))\n",
    "    print('Errorf u: %e' % (erroruinf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4cb6780",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T13:50:38.680603Z",
     "start_time": "2024-06-09T13:50:37.644347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randorm seed: 1235\n",
      "Error2 u: 6.328296e-04\n",
      "Error1 u: 3.356114e-04\n",
      "Errorf u: 1.817511e-03\n"
     ]
    }
   ],
   "source": [
    "    t = data['t'].flatten()[:,None][0:101] \n",
    "    x = data['x'].flatten()[:,None]\n",
    "    Exact = data['usol'][:,0:101]\n",
    "    \n",
    "    X, T = np.meshgrid(x,t)\n",
    "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "    u_star = Exact.T.flatten()[:,None]\n",
    "    u_pred ,_= model2.predict(X_star[:,0:1],X_star[:,1:2])\n",
    "\n",
    "    erroru = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "    erroru1 = np.linalg.norm(u_star-u_pred,1)/len(X_star)\n",
    "    erroruinf = np.linalg.norm(u_star-u_pred,np.inf)\n",
    "    \n",
    "    print('randorm seed: %d' % (RandomSeed))\n",
    "    print('Error2 u: %e' % (erroru))\n",
    "    print('Error1 u: %e' % (erroru1))\n",
    "    print('Errorf u: %e' % (erroruinf))\n",
    "    U_pred=u_pred.reshape(101,512).T\n",
    "    U_preds=U_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "970d25a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T13:50:40.239121Z",
     "start_time": "2024-06-09T13:50:38.695603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randorm seed: 1235\n",
      "Error2 u: 9.407912e-03\n",
      "Error1 u: 2.587443e-03\n",
      "Errorf u: 4.124001e-02\n"
     ]
    }
   ],
   "source": [
    "    t = data['t'].flatten()[:,None]\n",
    "    x = data['x'].flatten()[:,None]\n",
    "    Exact = data['usol']\n",
    "    \n",
    "    X, T = np.meshgrid(x,t)\n",
    "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "    u_star = Exact.T.flatten()[:,None]\n",
    "    u_pred ,f_pred= model2.predict(X_star[:,0:1],X_star[:,1:2])\n",
    "\n",
    "    erroru = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "    erroru1 = np.linalg.norm(u_star-u_pred,1)/len(X_star)\n",
    "    erroruinf = np.linalg.norm(u_star-u_pred,np.inf)\n",
    "    \n",
    "    print('randorm seed: %d' % (RandomSeed))\n",
    "    print('Error2 u: %e' % (erroru))\n",
    "    print('Error1 u: %e' % (erroru1))\n",
    "    print('Errorf u: %e' % (erroruinf))\n",
    "    U_pred=u_pred.reshape(201,512).T\n",
    "    U_preds=U_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e978439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T13:50:46.676946Z",
     "start_time": "2024-06-09T13:50:46.670943Z"
    }
   },
   "outputs": [],
   "source": [
    "    scipy.io.savemat(\"sedpinn.mat\", {'u': u_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4755ac7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T13:50:46.883943Z",
     "start_time": "2024-06-09T13:50:46.870944Z"
    }
   },
   "outputs": [],
   "source": [
    "    scipy.io.savemat(\"sedf.mat\", {'u': f_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb03c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745b99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5c47c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5fb65e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54e275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55142ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186f55e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f1d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf5676f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d7c5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8399fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8514e09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cecee1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647b413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52067397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
